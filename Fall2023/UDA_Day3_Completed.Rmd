---
html_document:
  toc: yes
author: "Unstructured Data Analytics, Fall 2023"
output:
  html_document:
    df_print: paged
always_allow_html: yes
title: 'UDA Challenge Lab: Processing & Visualizing Text'
toc_float: yes
theme: spacelab
highlight: tango
df_print: paged
---
  
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```

#Today's Main Question:  

## Preliminaries
Load basic packages
```{r echo = TRUE, warning = FALSE, message = FALSE}
library(tidyverse)
library(tidytext)
```


# Start with the revised data: Prep it

You'll want to work in steps today

 1. Read in the revised data file as `dat`
 2. Create `dat_words` which is tokenized by individual words and only has relevant words. *Challenge:* also remove "words" that are 100% numbers / keep only the "words" that are characters or characters-and-numbers
 3. Create overall counts (all documents together) in `dat_counts`
 4. Create story-by-story counts in `story_counts`
 5. *Challenge:* Create sport-by-sport counts in `sport_counts`

We want 3-4 different dataframes so we can compare things below
```{r}
#read in data
dat <- read_csv("C:/Users/alanski/Downloads/UDA Fall 2023 Stories v2.csv")

#explore
glimpse(dat)

#tokenize and prep
dat_words <- dat %>% 
  unnest_tokens(output = words, input = story, token = "words") %>%
  
  #challenge removal; can also use pattern of "[a-zA-Z]+"
  filter(str_detect(words, pattern = "[:alpha:]")) %>%
  
  #stopwords, using all lexicons; 
  ## okay to limit before joining or to limit using baseR within the antijoin 
  anti_join(stop_words, by = c("words" = "word"))
  ## limiting within looks like: stop_words[stop_words$lexicon == "SMART", ]

#create count-based data frames
dat_counts <- dat_words %>% count(words)
story_counts <- dat_words %>% group_by(id, words) %>% summarize(count = n())

#challenge count
sport_counts <- dat_words %>% mutate(sport = tolower(sport)) %>%
  group_by(sport, words) %>% summarize(count = n())

```

# Task 1: Create a wordcloud to visualize your data
## Everyone loves a good wordcloud

Yes, you can do this manually in ggplot by setting different random x and y values for each word and then replacing a scatterplot point with the word itself but... that's a lot of work.

Instead. use this new-to-you package
```{r echo = FALSE, eval = FALSE}
# you'll probably need to install this package
# this chunk of code will be ignored when you knit 
install.packages("wordcloud")
```

```{r}
#load new package
library(wordcloud)
```


Take a look at the help file for the wordcloud function.  

```{r echo = FALSE, eval = FALSE}
#view help
help(wordcloud)
```


  
  
You'll need to use a minimum of two arguments: 

1. the dataframe column that has your words for the "words" argument (use $ notation in the function)  
2. the dataframe column that has your counts for the "freq" argument (use $ notation in the function)  
  
After you get those two arguments working, look at the help page and try out two MORE optional arguments. These arguments will (in some way) change the appearance of your plots.  
  
  
*Use the dat_counts data*  
  
Note that the 2D position of the words is random by default.  
If you want a consistent placement, set a seed before you build the wordcloud  
(And if you don't like the picture it makes, try different seeds)  
```{r}
#your wordcloud here
wordcloud(dat_counts$words, freq = dat_counts$n,
          
          # supply a vector of color names (small N to large N)
          # or supply a column from the data, like dat_counts$n
          # you can get fancy and work with color palettes, using RColorBrewer
          colors = c("lightblue", "darkgreen", "darkblue"),
          
          # to change the size-range allowed for words
          # put the bigger number first
          scale = c(4, 0.25),
          
          # either one of these arguments will limit the words
          #min.freq = 6,
          max.words = 40)
```



#### Put on your Data Viz hat. How did your two "optional arguments" affect the preattentive qualities of your visualization? Are your updates better than the default arguments? Why/why not?



  
# Task 2: ggplot to visualize count data  
  
Note: the behavior of your data below will depend a little bit on how you created your counts above. If you use `group_by`, your data will retain a grouped structure by default.  If you use `count`, your data will be treated like a standard dataframe instead of structurally grouped.  
  
## Plot 1

*Start with the full data: `dat_counts` and build up your code piece by piece*
  
 * Can you create a bar chart that shows words and their wordcounts?  
 * Can you limit your bar chart to show only the top (x) words? (Pick a value for X)
 * Can you customize the title?
 * *Challenge:* Can you flip your axes so the words are on the y-axis and the counts are on the x-axis? (look it up!)
 * *Challenge:* Can you automatically sort the bars from most-to-fewest? This needs to happen within a *mutate* using the `reorder` function (look it up!) 


```{r}
#ggplot bar chart #1

#data
dat_counts %>%  #start with the data
  
#top X words
  slice_max(order_by = n, n = 20) %>%  
  
#challenge - sort them in a way that will "stick" for ggplot below  
  # this is actually a function for factors, that is setting the factor levels for words based on n
  mutate(words = reorder(words, n)) %>%
  
#start the plot
  ggplot(.,
         
  #use the words as X and the count colunn for Y
         aes(x = words, y = n)) +
  
  #you can use col or bar (but bar needs the stat = "identity" for pre-counted data) 
  #you do NOT need both
  geom_col() +
  geom_bar(stat = "identity") +  
  
  #challenge -- swap axes
  #this needs to be googled probably "how to flip axes in ggplot" or something
  coord_flip() +
  
  #title
  ggtitle("Top 20 words in UDA Fall 2023 stories") +
  
  #Additional cleanup (not required)
  ylab("count") + #remember, N is the original y axis -- yes flipping is weird
  theme_minimal()



```

#### Question:  Are there any key subjects or ideas that pop out when you look at the most common words?  
    
  
## Plot 2

*Switch to the `story_counts` or `sport_counts` data* 
  
 * Start with the same code as above; consider a smaller value of (X) for space and legibility
 * *Challenge:* Do you see each story or sport separately? If not, can you add a `facet_wrap` to your plot?  Can you use an argument inside `facet_wrap` to show only the relevant words for each chart?
 * *Challenge:* Can you get sorting working for each facet? You'll need the tidytext function `reorder_within` (look it up!) instead of the `reorder` you used before.

Are your facets tiny? You can make them bigger by adding dimensions to the {r} bar at the top, like this: {r fig.height = 14, fig.width=8}.  And you can also change the number of rows or columns for the plot of facets if you add relevant arguments inside facet_wrap 

```{r}
#ggplot bar chart #2 -- sports option

#data
sport_counts %>%  #start with the data
  
#top X words
  slice_max(order_by = count, n = 5) %>%  
  
#use the reorder_within function from the tidytext package 
  # regular reorder works for 1 big dataset
  # reorder within works when we want different orders by groups   
  mutate(words = reorder_within(x = words, by = count, within = sport)) %>%
  
#start the plot
  ggplot(.,
         
  #use the words as X and the count colunn for Y
         aes(x = words, y = count)) +
  
  #you can use col or bar (but bar needs the stat = "identity" for pre-counted data) 
  #you do NOT need both
  geom_col() +
  geom_bar(stat = "identity") +  
  
  #challenge -- swap axes
  #this needs to be googled probably "how to flip axes in ggplot" or something
  coord_flip() +
  
  #title
  ggtitle("Top 5 words in each sport") +
  
  #Additional cleanup (not required)
  ylab("count") + #remember, N is the original y axis -- yes flipping is weird
  theme_minimal() +
  
# #New challenge section
  # add a facet_wrap -- set the scales so it looks good
  facet_wrap(~sport, scales = "free") +
  
  # then add this so each plot will sort separately --- but we ALSO need an adjustment above
  scale_x_reordered()


```

```{r fig.height = 14, fig.width=8}
#ggplot bar chart #2 -- stories option

#data
story_counts %>%  #start with the data
  
#top X words
  slice_max(order_by = count, n = 4) %>%  
  
  #filter(count >= 2) %>%
  
#use the reorder_within function from the tidytext package 
  # regular reorder works for 1 big dataset
  # reorder within works when we want different orders by groups   
  mutate(words = reorder_within(x = words, by = count, within = id)) %>%
  
#start the plot
  ggplot(.,
         
  #use the words as X and the count colunn for Y
         aes(x = words, y = count)) +
  
  #you can use col or bar (but bar needs the stat = "identity" for pre-counted data) 
  #you do NOT need both
  geom_col() +
  geom_bar(stat = "identity") +  
  
  #challenge -- swap axes
  #this needs to be googled probably "how to flip axes in ggplot" or something
  coord_flip() +
  
  #title
  ggtitle("Top 4 words in each story") +
  
  #Additional cleanup (not required)
  ylab("count") + #remember, N is the original y axis -- yes flipping is weird
  theme_minimal() +
  
# #New challenge section
  # add a facet_wrap -- set the scales so it looks good
  facet_wrap(~id, scales = "free", nrow = 7, ncol = 5) +
  
  # then add this so each plot will sort separately --- but we ALSO need an adjustment above
  scale_x_reordered()


```



#### Question: Can you find any facets where the top words help you ID the sport, even if the sport name is missing or if you ignored it?  





#### Question: Pick 2-3 stories or sports and look at their keywords in particular.  Is there any kind of theme for the story or for the sport that comes out?  
Remember that our top words for Story 1 showed that family and time were key ideas, through top words like "brother" and "year".   
  
*This kind of analysis works better with a lot more data, but you get the idea*  


 


#### Question: Compare the top words in the small graphs to each other, or to the larger graph (with all the data together).  Comment on something interesting.  Literally anything interesting.  Text analysis is more like English class than Stats some of the time.

